{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Example for adamantane-1,3,5,7-tetracarboxylic acid (ADTA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from xca.data_synthesis.builder import cycle_params\n",
    "from xca.data_synthesis.cctbx import load_cif, calc_structure_factor, convert_to_numpy\n",
    "from xca.ml.tf_data_proc import dir2TFR, build_test_dataset\n",
    "from xca.ml.tf_models import CNN_training as training\n",
    "from xca.ml.tf_parameters import load_hyperparameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The following functions will help generate a synthetic dataset.\n",
    "These are largely replicates of the contents of `example_scripts`, placed in notebooks for more accessible visibility.\n",
    "\n",
    "The default `N_PATTERNS` is set to 100 for convenience in testing. To reproduce the work of arXiv:2008.00283,\n",
    "change this to 50,000."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "N_PATTERNS = 100\n",
    "system = \"ADTA\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_reflections(cif_path, tth_min, tth_max, wavelength):\n",
    "    \"\"\"Checks relevant reflections that occur between tth_min and tth_max at a given wavelength\"\"\"\n",
    "    data = load_cif(cif_path)\n",
    "    sf = calc_structure_factor(data['structure'])\n",
    "    scattering = convert_to_numpy(sf, wavelength=wavelength, tth_max=tth_max, tth_min=tth_min)\n",
    "    reflections = zip(scattering['hkl'], scattering['2theta'], scattering['I'])\n",
    "    keep = []\n",
    "    for reflection in reflections:\n",
    "        if reflection[1] < tth_max and reflection[1] > tth_min and reflection[2] > 1:\n",
    "            keep.append(tuple(reflection[0]))\n",
    "    return keep\n",
    "\n",
    "\n",
    "def log_reflections(cif_paths, tth_min, tth_max, wavelength, outpath=None):\n",
    "    \"\"\"Itterates over list of cifs and puts relevant reflections into json file\"\"\"\n",
    "    dic = {}\n",
    "    for cif_path in cif_paths:\n",
    "        if not isinstance(cif_path, Path):\n",
    "            path = Path(cif_path)\n",
    "        else:\n",
    "            path = cif_path\n",
    "        dic[path.stem] = get_reflections(path, tth_min, tth_max, wavelength)\n",
    "    if outpath:\n",
    "        with open(outpath, 'w') as f:\n",
    "            json.dump(dic, f)\n",
    "\n",
    "    return dic\n",
    "\n",
    "def pattern_simulation(n_patterns):\n",
    "    \"\"\"Example pattern simulation as reported in arXiv:2008.00283\"\"\"\n",
    "    wavelength = 1.54060\n",
    "    param_dict = {'noise_std': 2e-3,\n",
    "                  'instrument_radius': 240.00,\n",
    "                  '2theta_min': 2.00756514,\n",
    "                  '2theta_max': 39.99347292,\n",
    "                  'n_datapoints': 2894}\n",
    "    kwargs = {'bkg_-1': (0.0, 0.5),\n",
    "              'bkg_-2': (0.0, 1.0)}\n",
    "    march_range = (0.05, 1)\n",
    "    sample_height = (-2, 2)\n",
    "    shape_limit = 0.05\n",
    "    cif_paths = list(Path(f'../example_scripts/cifs-{system}/').glob('*.cif'))\n",
    "    reflections = log_reflections(cif_paths, param_dict['2theta_min'], param_dict['2theta_max'], wavelength)\n",
    "    for idx, cif in enumerate(cif_paths):\n",
    "        print(cif)\n",
    "        phase = cif.stem\n",
    "        param_dict['input_cif'] = cif\n",
    "        output_path = Path(f'./tmp/{system}') / str(idx)\n",
    "        output_path.mkdir(parents=True, exist_ok=True)\n",
    "        cycle_params(n_patterns,\n",
    "                     output_path,\n",
    "                     input_params=param_dict,\n",
    "                     march_range=march_range,\n",
    "                     shape_limit=shape_limit,\n",
    "                     sample_height=sample_height,\n",
    "                     preferred_axes=reflections[phase],\n",
    "                     **kwargs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Simulate the patterns\n",
    "These patterns are output as numpy files, which are converted to tensorflow records for convenience.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pattern_simulation(N_PATTERNS)\n",
    "dir2TFR(f\"./tmp/{system}\", f\"./tmp/{system}.tfrecords\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training from this new dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "params = load_hyperparameters(params_file=f\"../example_scripts/{system}_training.json\")\n",
    "res, model = training(params=params)\n",
    "print(f\"Results for {system}\")\n",
    "print(res)\n",
    "model.save(f\"./tmp/{system}_model\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Now we segregate the test data based on this trained model\n",
    "The output here is a dictionary where the keys are the ground truth classification,\n",
    "and the values are the counts of argmax predictions for all of the patterns that correspond to that class."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_params = {}\n",
    "test_params.update(params)\n",
    "test_params['dataset_path'] = '../example_data/ADTA.tfrecords'\n",
    "test_dataset = build_test_dataset(test_params)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classifications = {}\n",
    "for batch in test_dataset:\n",
    "    label = batch['label'].numpy()[0].decode(\"utf-8\")\n",
    "    if label not in classifications:\n",
    "        classifications[label] = np.zeros(params['n_classes'])\n",
    "\n",
    "    y_pred = model({'X':batch['X']}, training=False)\n",
    "    classifications[label][np.argmax(y_pred)] += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classifications"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}