{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Example for Ni-Co-Al ternary alloy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from xca.data_synthesis.builder import cycle_params\n",
    "from xca.data_synthesis.cctbx import load_cif, calc_structure_factor, convert_to_numpy\n",
    "from xca.ml.tf_data_proc import dir2TFR, build_test_dataset\n",
    "from xca.ml.tf_models import CNN_training as training\n",
    "from xca.ml.tf_parameters import load_hyperparameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The following functions will help generate a synthetic dataset.\n",
    "These are largely replicates of the contents of `example_scripts`, placed in notebooks for more accessible visibility.\n",
    "\n",
    "The default `N_PATTERNS` is set to 100 for convenience in testing. To reproduce the work of arXiv:2008.00283,\n",
    "change this to 50,000."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "N_PATTERNS = 100\n",
    "system = \"NiCoAl\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_reflections(cif_path, tth_min, tth_max, wavelength):\n",
    "    \"\"\"Checks relevant reflections that occur between tth_min and tth_max at a given wavelength\"\"\"\n",
    "    data = load_cif(cif_path)\n",
    "    sf = calc_structure_factor(data['structure'])\n",
    "    scattering = convert_to_numpy(sf, wavelength=wavelength, tth_max=tth_max, tth_min=tth_min)\n",
    "    reflections = zip(scattering['hkl'], scattering['2theta'], scattering['I'])\n",
    "    keep = []\n",
    "    for reflection in reflections:\n",
    "        if reflection[1] < tth_max and reflection[1] > tth_min and reflection[2] > 1:\n",
    "            keep.append(tuple(reflection[0]))\n",
    "    return keep\n",
    "\n",
    "\n",
    "def log_reflections(cif_paths, tth_min, tth_max, wavelength, outpath=None):\n",
    "    \"\"\"Itterates over list of cifs and puts relevant reflections into json file\"\"\"\n",
    "    dic = {}\n",
    "    for cif_path in cif_paths:\n",
    "        if not isinstance(cif_path, Path):\n",
    "            path = Path(cif_path)\n",
    "        else:\n",
    "            path = cif_path\n",
    "        dic[path.stem] = get_reflections(path, tth_min, tth_max, wavelength)\n",
    "    if outpath:\n",
    "        with open(outpath, 'w') as f:\n",
    "            json.dump(dic, f)\n",
    "\n",
    "    return dic\n",
    "\n",
    "def pattern_simulation(n_patterns):\n",
    "    \"\"\"Example pattern simulation as reported in arXiv:2008.00283\"\"\"\n",
    "    wavelength = [(1.54060, 0.5), (1.54439, 0.5)]\n",
    "    param_dict = {'noise_std': 5e-3,\n",
    "                  'instrument_radius': 240.00,\n",
    "                  'theta_m': 26.6,\n",
    "                  '2theta_min': 20.0,\n",
    "                  '2theta_max': 89.93999843671914,\n",
    "                  'n_datapoints': 3498}\n",
    "    kwargs = {'bkg_0': (0.0, 0.05)}\n",
    "    march_range = (0.05, 1)\n",
    "    sample_height = (-2.0, 2.0)\n",
    "    shape_limit = 0.05\n",
    "    cif_paths = list(Path(f'../example_scripts/cifs-{system}/').glob('*.cif'))\n",
    "    reflections = log_reflections(cif_paths, param_dict['2theta_min'], param_dict['2theta_max'], wavelength[0][0])\n",
    "    filemap = {}\n",
    "    for idx, cif in enumerate(cif_paths):\n",
    "        print(cif)\n",
    "        phase = cif.stem\n",
    "        param_dict['input_cif'] = cif\n",
    "        output_path = Path(f'./tmp/{system}') / str(idx)\n",
    "        output_path.mkdir(parents=True, exist_ok=True)\n",
    "        cycle_params(n_patterns,\n",
    "                     output_path,\n",
    "                     input_params=param_dict,\n",
    "                     march_range=march_range,\n",
    "                     shape_limit=shape_limit,\n",
    "                     sample_height=sample_height,\n",
    "                     preferred_axes=reflections[phase],\n",
    "                     **kwargs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Simulate the patterns\n",
    "These patterns are output as numpy files, which are converted to tensorflow records for convenience.\n",
    "The file names in this case are used to track key information which is stored in a dictionary.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pattern_simulation(N_PATTERNS)\n",
    "dir2TFR(f\"./tmp/{system}\", f\"./tmp/{system}.tfrecords\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training from this new dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "params = load_hyperparameters(params_file=f\"../example_scripts/{system}_training.json\")\n",
    "res, model = training(params=params)\n",
    "print(f\"Results for {system}\")\n",
    "print(res)\n",
    "model.save(f\"./tmp/{system}_model\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Now we segregate the test data based on this trained model\n",
    "The output here is a dictionary where the keys are the ground truth classification,\n",
    "and the values are the counts of argmax predictions for all of the patterns that correspond to that class."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_params = {}\n",
    "test_params.update(params)\n",
    "test_params['dataset_path'] = '../example_data/NiCoAl.tfrecords'\n",
    "test_dataset = build_test_dataset(test_params)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "classifications = {}\n",
    "for batch in test_dataset:\n",
    "    label = batch['label'].numpy()[0].decode(\"utf-8\")\n",
    "    if label not in classifications:\n",
    "        classifications[label] = np.zeros(params['n_classes'])\n",
    "\n",
    "    y_pred = model({'X':batch['X']}, training=False)\n",
    "    classifications[label][np.argmax(y_pred)] += 1\n",
    "classifications"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Mappings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cif_paths = list(Path(f'../example_scripts/cifs-{system}/').glob('*.cif'))\n",
    "filemap = {}\n",
    "elements = ('Ni','Co','Al')\n",
    "for idx, cif in enumerate(cif_paths):\n",
    "    filemap[idx]={}\n",
    "    name, syst, num = str(cif.stem).split('-')\n",
    "    filemap[idx]['name'] = name\n",
    "    filemap[idx]['crystal-system'] = syst\n",
    "    filemap[idx]['space-group'] = int(num)\n",
    "    filemap[idx]['composition'] = {}\n",
    "    for e in elements:\n",
    "        # Uses the first (assuming only) instance of the element in formula name to get composition\n",
    "        p = re.compile('{}[0-9]*\\.?[0-9]*'.format(e))\n",
    "        comp = p.findall(name)\n",
    "        if comp:\n",
    "            x = comp[0].replace(e,'')\n",
    "            if x:\n",
    "                filemap[idx]['composition'][e] = float(x)\n",
    "            else: #Empty string after removal means only 1 of element\n",
    "                filemap[idx]['composition'][e] = 1.\n",
    "        else: # Empty list\n",
    "            filemap[idx]['composition'][e] = 0.\n",
    "    s = sum(filemap[idx]['composition'].values())\n",
    "    for e in elements:\n",
    "        filemap[idx]['composition'][e] /= s"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sim_mapping = {}\n",
    "sim_mapping_rev = {}\n",
    "for key in filemap:\n",
    "    sim_mapping[int(key)] = filemap[key]['name']+'-'+str(filemap[key]['space-group'])\n",
    "    sim_mapping_rev[filemap[key]['name']+'-'+str(filemap[key]['space-group'])] = int(key)\n",
    "sim_mapping"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Constructing a full output of the probability distributions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def EDX_proby(path):\n",
    "    def gaussian(x, sigma=0.1164977062):\n",
    "        \"\"\"\n",
    "        Calculates gaussian function centered at (0,1).\n",
    "        https://en.wikipedia.org/wiki/Gaussian_function\n",
    "        Default Full-Width-Tenth-Max = 0.5\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: float or array-like\n",
    "        sigma: float\n",
    "            standard deviation or sqrt(variance) of function\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        probability density: type of x\n",
    "        \"\"\"\n",
    "        return np.exp(-np.power(x, 2.) / (2 * np.power(sigma, 2.)))\n",
    "    EDX_df = pd.read_csv(path, index_col='Number')\n",
    "    EDX_df.iloc[:,:] /= 100\n",
    "    df = pd.DataFrame(index=EDX_df.index)\n",
    "    for key in filemap:\n",
    "        prod = np.ones(len(EDX_df))\n",
    "        for elem, value in filemap[key]['composition'].items():\n",
    "            prod *= gaussian(EDX_df[elem].values - value)\n",
    "        df[filemap[key]['name']] = prod\n",
    "\n",
    "    df.iloc[:,:]=df.iloc[:,:].div(df.iloc[:,:].sum(axis=1),axis=0)\n",
    "\n",
    "    return df,EDX_df\n",
    "edx_proby, comp = EDX_proby(path='../example_data/EDXmap.csv')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "XRD_all = {}\n",
    "joint_all = {}\n",
    "for batch in test_dataset:\n",
    "    label = batch['label'].numpy()[0].decode(\"utf-8\")\n",
    "    label_split = list(label.split('+'))\n",
    "    fnum = int(os.path.splitext(batch['fname'].numpy()[0].decode(\"utf-8\"))[0])\n",
    "    fname = batch['fname'].numpy()[0].decode(\"utf-8\")\n",
    "    XRD_pred = model({'X':batch['X']}, training=False).numpy()[0,:]\n",
    "\n",
    "    joint_pred = np.copy(XRD_pred)\n",
    "    # This loops over each prediction to allow for multiple phases of same composition\n",
    "    for idx in range(len(joint_pred)):\n",
    "        joint_pred[idx] *= edx_proby.loc[fnum][filemap[idx]['name']]\n",
    "    joint_pred /= np.sum(joint_pred)\n",
    "\n",
    "    XRD_all[fname] = (label,XRD_pred[:])\n",
    "    joint_all[fname] = (label,joint_pred[:])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def write_csv(path, dic):\n",
    "    with open(path,'w') as f:\n",
    "        f.write(\"Numpy idx, True Phase, \")\n",
    "        for idx in range(len(filemap)):\n",
    "            f.write(\"{}, \".format(filemap[idx]['name']))\n",
    "        f.write('\\n')\n",
    "        f.write(\", Space Group, \")\n",
    "        for idx in range(len(filemap)):\n",
    "            f.write(\"{}, \".format(filemap[idx]['space-group']))\n",
    "        f.write('\\n')\n",
    "        f.write(\", Crystal System, \")\n",
    "        for idx in range(len(filemap)):\n",
    "            f.write(\"{}, \".format(filemap[idx]['crystal-system']))\n",
    "        f.write('\\n')\n",
    "\n",
    "        for key in sorted(dic.keys(), key=lambda x: int(x[:-4])):\n",
    "            true, preds = dic[key]\n",
    "            f.write(\"{}, {}, {}\\n\".format(key[:-4], true.replace(',','/'), \", \".join([\"{:.3e}\".format(p) for p in preds])))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "write_csv('./tmp/NiCoAl_xrd_pred.csv', XRD_all)\n",
    "write_csv('./tmp/NiCoAl_joint_pred.csv', joint_all)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}