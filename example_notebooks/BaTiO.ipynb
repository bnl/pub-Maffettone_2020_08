{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Example for BaTiO$_3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from xca.data_synthesis.builder import cycle_params\n",
    "from xca.data_synthesis.cctbx import load_cif, calc_structure_factor, convert_to_numpy\n",
    "from xca.ml.tf_data_proc import dir2TFR\n",
    "from xca.ml.tf_models import CNN_training as training\n",
    "from xca.ml.tf_parameters import load_hyperparameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The following functions will help generate a synthetic dataset.\n",
    "These are largely replicates of the contents of `example_scripts`, placed in notebooks for more accessible visibility.\n",
    "\n",
    "The default `N_PATTERNS` is set to 100 for convenience in testing. To reproduce the work of arXiv:2008.00283,\n",
    "change this to 50,000."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "N_PATTERNS = 100\n",
    "system = \"BaTiO\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_reflections(cif_path, tth_min, tth_max, wavelength):\n",
    "    \"\"\"Checks relevant reflections that occur between tth_min and tth_max at a given wavelength\"\"\"\n",
    "    data = load_cif(cif_path)\n",
    "    sf = calc_structure_factor(data['structure'])\n",
    "    scattering = convert_to_numpy(sf, wavelength=wavelength, tth_max=tth_max, tth_min=tth_min)\n",
    "    reflections = zip(scattering['hkl'], scattering['2theta'], scattering['I'])\n",
    "    keep = []\n",
    "    for reflection in reflections:\n",
    "        if reflection[1] < tth_max and reflection[1] > tth_min and reflection[2] > 1:\n",
    "            keep.append(tuple(reflection[0]))\n",
    "    return keep\n",
    "\n",
    "\n",
    "def log_reflections(cif_paths, tth_min, tth_max, wavelength, outpath=None):\n",
    "    \"\"\"Itterates over list of cifs and puts relevant reflections into json file\"\"\"\n",
    "    dic = {}\n",
    "    for cif_path in cif_paths:\n",
    "        if not isinstance(cif_path, Path):\n",
    "            path = Path(cif_path)\n",
    "        else:\n",
    "            path = cif_path\n",
    "        dic[path.stem] = get_reflections(path, tth_min, tth_max, wavelength)\n",
    "    if outpath:\n",
    "        with open(outpath, 'w') as f:\n",
    "            json.dump(dic, f)\n",
    "\n",
    "    return dic\n",
    "\n",
    "def pattern_simulation(n_patterns):\n",
    "    \"\"\"Example pattern simulation as reported in arXiv:2008.00283\"\"\"\n",
    "    wavelength = 0.1671\n",
    "    param_dict = {'wavelength': 0.1671,\n",
    "                  'noise_std': 5e-4,\n",
    "                  'instrument_radius': 1065.8822732979447,\n",
    "                  'theta_m': 0.0,\n",
    "                  '2theta_min': 0.011231808788013649,\n",
    "                  '2theta_max': 24.853167100343246,\n",
    "                  'n_datapoints': 3488}\n",
    "    kwargs = {'bkg_1': (-1e-4, 1e-4),\n",
    "              'bkg_0': (0, 1e-3)}\n",
    "    cif_paths = list(Path(f'../example_scripts/cifs-{system}/').glob('*.cif'))\n",
    "    march_range = (0.8, 1.0)\n",
    "    sample_height = (-2.0, 2.0)\n",
    "    shape_limit = 1e-1\n",
    "    reflections = log_reflections(cif_paths, param_dict['2theta_min'], param_dict['2theta_max'], wavelength)\n",
    "    for idx, cif in enumerate(cif_paths):\n",
    "        print(cif)\n",
    "        phase = cif.stem\n",
    "        param_dict['input_cif'] = cif\n",
    "        output_path = Path(f'./tmp/{system}') / str(idx)\n",
    "        output_path.mkdir(parents=True, exist_ok=True)\n",
    "        cycle_params(n_patterns,\n",
    "                     output_path,\n",
    "                     input_params=param_dict,\n",
    "                     march_range=march_range,\n",
    "                     shape_limit=shape_limit,\n",
    "                     sample_height=sample_height,\n",
    "                     preferred_axes=reflections[phase],\n",
    "                     **kwargs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Simulate the patterns\n",
    "These patterns are output as numpy files, which are converted to tensorflow records for convenience.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pattern_simulation(N_PATTERNS)\n",
    "dir2TFR(f\"./tmp/{system}\", f\"./tmp/{system}.tfrecords\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training from this new dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "params = load_hyperparameters(params_file=f\"../example_scripts/{system}_training.json\")\n",
    "res, model = training(params=params)\n",
    "print(f\"Results for {system}\")\n",
    "print(res)\n",
    "model.save(f\"./tmp/{system}_model\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Now we segregate the test data based on this trained model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "exp = np.loadtxt('../example_data/BaTiO.csv', delimiter=',', skiprows=1)\n",
    "temperatures = []\n",
    "with open('../example_data/BaTiO.csv', 'r') as f:\n",
    "    names = f.readline().split(',')\n",
    "    for name in names:\n",
    "        temperatures.append(float(name.split('_')[1][:-1]))\n",
    "exp = tf.reshape(tf.convert_to_tensor(exp, dtype=tf.float32), (60, 3488, 1))\n",
    "y_pred = model({'X': exp}, training=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for i in range(y_pred.shape[1]):\n",
    "    plt.plot(y_pred[:,i])\n",
    "plt.xticks(range(0, 60, 19), [temperatures[i] for i in range(0, 60, 19)])\n",
    "plt.xlabel('Temperature [K]')\n",
    "plt.ylabel('Phase probability')\n",
    "plt.ylim(0,1)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}